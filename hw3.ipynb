{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "morph = MorphAnalyzer()\n",
    "stops = set(stopwords.words('russian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# скачаем данные в папке data и распакуем их\n",
    "PATH_TO_DATA = './data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [os.path.join(PATH_TO_DATA, file) for file in os.listdir(PATH_TO_DATA)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([pd.read_json(file, lines=True, encoding='UTF-8') for file in files], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"keywords\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(true_kws, predicted_kws):\n",
    "    assert len(true_kws) == len(predicted_kws)\n",
    "    \n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1s = []\n",
    "    jaccards = []\n",
    "    \n",
    "    for i in range(len(true_kws)):\n",
    "        true_kw = set(true_kws[i])\n",
    "        predicted_kw = set(predicted_kws[i])\n",
    "        \n",
    "        tp = len(true_kw & predicted_kw)\n",
    "        union = len(true_kw | predicted_kw)\n",
    "        fp = len(predicted_kw - true_kw)\n",
    "        fn = len(true_kw - predicted_kw)\n",
    "        \n",
    "        if (tp+fp) == 0:\n",
    "            prec = 0\n",
    "        else:\n",
    "            prec = tp / (tp + fp)\n",
    "        \n",
    "        if (tp+fn) == 0:\n",
    "            rec = 0\n",
    "        else:\n",
    "            rec = tp / (tp + fn)\n",
    "        if (prec+rec) == 0:\n",
    "            f1 = 0\n",
    "        else:\n",
    "            f1 = (2*(prec*rec))/(prec+rec)\n",
    "            \n",
    "        jac = tp / union\n",
    "        \n",
    "        precisions.append(prec)\n",
    "        recalls.append(rec)\n",
    "        f1s.append(f1)\n",
    "        jaccards.append(jac)\n",
    "    print('Precision - ', round(np.mean(precisions), 2))\n",
    "    print('Recall - ', round(np.mean(recalls), 2))\n",
    "    print('F1 - ', round(np.mean(f1s), 2))\n",
    "    print('Jaccard - ', round(np.mean(jaccards), 2))\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Способ 1: использовать именительный падеж вместо нормальной формы, уменьшить min_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "punct = punctuation+'«»—…“”*№–'\n",
    "stops = set(stopwords.words('russian'))\n",
    "\n",
    "def normalize(text):\n",
    "    \n",
    "    words = [word.strip(punct) for word in text.lower().split()]\n",
    "    words = [morph.parse(word)[0] for word in words if word and word not in stops]\n",
    "    words = [word.inflect({'nomn'}) for word in words if word.tag.POS == 'NOUN' or word.tag.POS == \"ADJS\" or word.tag.POS == \"ADJF\"]\n",
    "    words = [word.word for word in words if word is not None]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['content_norm'] = data['content'].apply(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['content_norm2'] = data['content_norm'].apply(' '.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(ngram_range=(1,2), min_df=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['яблоко',\n",
       "  'молодёжное яблоко',\n",
       "  'молодёжное',\n",
       "  'акция',\n",
       "  'активисты',\n",
       "  'молодёжный',\n",
       "  'дарья',\n",
       "  'наши активисты',\n",
       "  'молодые люди',\n",
       "  'деятельность'],\n",
       " ['млрд куб',\n",
       "  'куб',\n",
       "  'газпром',\n",
       "  'газа',\n",
       "  'млрд',\n",
       "  'добыча газа',\n",
       "  'добыча',\n",
       "  'независимые производители',\n",
       "  'холдинг',\n",
       "  'производители'],\n",
       " ['роман',\n",
       "  'мениппея',\n",
       "  'книга',\n",
       "  'жанр',\n",
       "  'стихотворения',\n",
       "  'поэзия',\n",
       "  'книги',\n",
       "  'перевод',\n",
       "  'герои',\n",
       "  'туманов страница']]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.fit(data['content_norm2'])\n",
    "id2word = {i:word for i,word in enumerate(tfidf.get_feature_names())}\n",
    "texts_vectors = tfidf.transform(data['content_norm2'])\n",
    "# сортировка по убыванию, поэтому нужно развернуть список\n",
    "keywords = [[id2word[w] for w in top] for top in texts_vectors.toarray().argsort()[:,:-11:-1]] \n",
    "keywords[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision -  0.14\n",
      "Recall -  0.26\n",
      "F1 -  0.17\n",
      "Jaccard -  0.1\n"
     ]
    }
   ],
   "source": [
    "evaluate(data['keywords'], keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сделаем граф направленным"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from itertools import combinations\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_matrix(text, window_size=5):\n",
    "    vocab = set(text)\n",
    "    word2id = {w:i for i, w in enumerate(vocab)}\n",
    "    id2word = {i:w for i, w in enumerate(vocab)}\n",
    "    # преобразуем слова в индексы для удобства\n",
    "    ids = [word2id[word] for word in text]\n",
    "\n",
    "    # создадим матрицу совстречаемости\n",
    "    m = np.zeros((len(vocab), len(vocab)))\n",
    "\n",
    "    # пройдемся окном по всему тексту\n",
    "    for i in range(0, len(ids), window_size):\n",
    "        window = ids[i:i+window_size]\n",
    "        # добавим единичку всем парам слов в этом окне\n",
    "        for j, k in combinations(window, 2):\n",
    "            # чтобы граф был направленный \n",
    "            m[j][k] += 1\n",
    "    \n",
    "    return m, id2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def some_centrality_measure(text, window_size=5, topn=5):\n",
    "    \n",
    "    matrix, id2word = build_matrix(text, window_size)\n",
    "    G = nx.from_numpy_array(matrix)\n",
    "    # тут можно поставить любую метрику\n",
    "    node2measure = dict(nx.degree(G))\n",
    "    \n",
    "    return [id2word[index] for index,measure in sorted(node2measure.items(), key=lambda x: -x[1])[:topn]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "keyword_nx = data['content_norm'].apply(lambda x: some_centrality_measure(x, 10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision -  0.14\n",
      "Recall -  0.26\n",
      "F1 -  0.17\n",
      "Jaccard -  0.1\n"
     ]
    }
   ],
   "source": [
    "evaluate(data['keywords'], keyword_nx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Как выяснилось, если в функцию nx.from_numpy_array(matrix) не задавать параметр create_using, независимо от матрицы (диагональную мы ей подаем или нет), в любом случае граф будет ненаправленный. Собственно, изменим код."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_build_matrix(text, window_size):\n",
    "    return build_matrix(text, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['matrix'] = data['content_norm'].apply(lambda x: x_build_matrix(x, 10)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['id2word'] = data['content_norm'].apply(lambda x: x_build_matrix(x, 10)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_kws(matrix):\n",
    "    G = nx.from_numpy_array(matrix, create_using=nx.DiGraph)\n",
    "    return dict(nx.degree(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures = data['matrix'].apply(lambda x: compute_kws(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_ids(id2word, node2measure, topn):\n",
    "    return [id2word[index] for index,measure in sorted(node2measure.items(), key=lambda x: -x[1])[:topn]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directed_kws = [return_ids(data['id2word'][i], measures[i], 10) for i in range(len(measures))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision -  0.14\n",
      "Recall -  0.26\n",
      "F1 -  0.17\n",
      "Jaccard -  0.1\n"
     ]
    }
   ],
   "source": [
    "evaluate(data['keywords'], directed_kws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте проверим, а изменилось ли что-то в результатах (потому что при предыдущем запуске эксперимента результаты только переранжировались)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set() set()\n",
      "set() set()\n",
      "{'стихотворения'} {'мениппея'}\n",
      "{'бывший'} {'рубли'}\n",
      "{'развитие'} {'новые'}\n",
      "{'ситуация'} {'который'}\n",
      "set() set()\n",
      "{'вопрос'} {'новый'}\n",
      "{'иран'} {'газовые'}\n",
      "set() set()\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(set.difference(set(directed_kws[i]), set(keyword_nx[i])), set.difference(set(keyword_nx[i]), set(directed_kws[i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Мы видим, что разница все-таки есть. Но не зря же я дробила код, чтобы потом не попробовать другие метрики? Давайте посмотрим на closeness centrality, betweenness centrality и eigenvector centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cc_kws(matrix):\n",
    "    G = nx.from_numpy_array(matrix, create_using=nx.DiGraph)\n",
    "    return dict(nx.closeness_centrality(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bc_kws(matrix):\n",
    "    G = nx.from_numpy_array(matrix, create_using=nx.DiGraph)\n",
    "    return dict(nx.betweenness_centrality(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ec_kws(matrix):\n",
    "    G = nx.from_numpy_array(matrix, create_using=nx.DiGraph)\n",
    "    return dict(nx.eigenvector_centrality(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures = data['matrix'].apply(lambda x: compute_cc_kws(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision -  0.1\n",
      "Recall -  0.2\n",
      "F1 -  0.13\n",
      "Jaccard -  0.07\n"
     ]
    }
   ],
   "source": [
    "cc_kws = [return_ids(data['id2word'][i], measures[i], 10) for i in range(len(measures))]\n",
    "evaluate(data['keywords'], cc_kws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision -  0.13\n",
      "Recall -  0.25\n",
      "F1 -  0.16\n",
      "Jaccard -  0.09\n"
     ]
    }
   ],
   "source": [
    "measures = data['matrix'].apply(lambda x: compute_bc_kws(x))\n",
    "bc_kws = [return_ids(data['id2word'][i], measures[i], 10) for i in range(len(measures))]\n",
    "evaluate(data['keywords'], bc_kws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оно, конечно, замечательно, но давайте попробуем что-то интересненькое"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import RAKE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anti_normalize(text):\n",
    "    words = [word.strip(punct) for word in text.lower().split()]\n",
    "    words = [morph.parse(word)[0] for word in words if word]\n",
    "    words = [word.word for word in words if word.tag.POS != 'NOUN' and word.tag.POS != \"ADJS\" and word.tag.POS != \"ADJF\" and word is not None]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['stops'] = data['content'].apply(lambda x: anti_normalize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['rakes'] = data['stops'].apply(lambda x: RAKE.Rake(list(set(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rake_kws = []\n",
    "for i in range(data.shape[0]):\n",
    "    rake_kws.append(data[\"rakes\"].tolist()[i].run(data['content'].tolist()[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rake_kws_0 = [[i[0] for i in row][:10] for row in rake_kws]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision -  0.0\n",
      "Recall -  0.0\n",
      "F1 -  0.0\n",
      "Jaccard -  0.0\n"
     ]
    }
   ],
   "source": [
    "evaluate(data['keywords'], rake_kws_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как-то не очень. попробуем как-то преобразовать результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = [normalize(' '.join([i[0] for i in r][:20])) for r in rake_kws]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_joined = [' '.join(i) for i in r]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['яблоко',\n",
       "  'молодёжное яблоко',\n",
       "  'молодёжное',\n",
       "  'молодые люди',\n",
       "  'молодые',\n",
       "  'молодёжный яблоко',\n",
       "  'задача молодёжный',\n",
       "  'кампания страна',\n",
       "  'арбатов нынешние',\n",
       "  'полные жизнь'],\n",
       " ['добыча газа',\n",
       "  'газа',\n",
       "  'цены',\n",
       "  'добыча',\n",
       "  'холдинг',\n",
       "  'технологии очередные',\n",
       "  'михаил занозины',\n",
       "  'суммарная добыча',\n",
       "  'обеспечение внутреннее',\n",
       "  'сильный козырь'],\n",
       " ['моя',\n",
       "  'наследник',\n",
       "  'александр',\n",
       "  'прозаик прямое',\n",
       "  'новеллы',\n",
       "  'евгений витковский',\n",
       "  'маркес',\n",
       "  'литература законный',\n",
       "  'маркес конец',\n",
       "  'памятные эти']]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_rake = TfidfVectorizer(ngram_range=(1,2), min_df=1)\n",
    "tfidf_rake.fit(r_joined)\n",
    "id2word_rake = {i:word for i,word in enumerate(tfidf_rake.get_feature_names())}\n",
    "texts_vectors_rake = tfidf_rake.transform(r_joined)\n",
    "# сортировка по убыванию, поэтому нужно развернуть список\n",
    "keywords_rake = [[id2word_rake[w] for w in top] for top in texts_vectors_rake.toarray().argsort()[:,:-11:-1]] \n",
    "keywords_rake[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision -  0.05\n",
      "Recall -  0.1\n",
      "F1 -  0.06\n",
      "Jaccard -  0.04\n"
     ]
    }
   ],
   "source": [
    "evaluate(data['keywords'], keywords_rake)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на textRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision -  0.05\n",
      "Recall -  0.11\n",
      "F1 -  0.07\n",
      "Jaccard -  0.04\n"
     ]
    }
   ],
   "source": [
    "kws_rake_rank = [some_centrality_measure(r_, 10, 10) for r_ in r]\n",
    "evaluate(data['keywords'], kws_rake_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['политика',\n",
       " 'люди',\n",
       " 'яблоко',\n",
       " 'молодые',\n",
       " 'ильдар',\n",
       " 'молодёжная',\n",
       " 'арбатов',\n",
       " 'опасная',\n",
       " 'страна',\n",
       " 'условия']"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kws_rake_rank[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ну, всяко лучше, чем ничего.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Попробуем TextRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from summa import keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textrank = data['content'].apply(lambda x: keywords.keywords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(data['keywords'], textrank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textrank_norm = data['content_norm2'].apply(lambda x: keywords.keywords(x))\n",
    "evaluate(data['keywords'], textrank_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_tx_kws = []\n",
    "for i in data['content_norm2'].tolist():\n",
    "    list_tx_kws.append(keywords.keywords(i).split('\\n')[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision -  0.07\n",
      "Recall -  0.13\n",
      "F1 -  0.09\n",
      "Jaccard -  0.05\n"
     ]
    }
   ],
   "source": [
    "evaluate(data['keywords'], list_tx_kws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получилось грустненько. Ну ничего, попробуем что-нибудь еще"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Попробуем викификацию от моей любимой Texterra. Вдруг она не подведет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import texterra\n",
    "t = texterra.API(\"c41d9b98960e6f6bdfb3452f6b174e5a6554f992\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как текстерра использует API, то, чтобы не DDOS-ить сервер, сделаем поменьше запросов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "texterra_kws = data['content_norm2'][:10].apply(lambda x: list(t.disambiguation(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "texterra_kws2 = data['content_norm2'][20:50].apply(lambda x: list(t.disambiguation(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_kws = [list(set([t[2] for t in kws[0]])) for kws in texterra_kws]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision -  0.06\n",
      "Recall -  0.45\n",
      "F1 -  0.1\n",
      "Jaccard -  0.05\n"
     ]
    }
   ],
   "source": [
    "evaluate(data['keywords'][:10], t_kws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_kws2 = [list(set([t[2] for t in kws[0]])) for kws in texterra_kws2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision -  0.06\n",
      "Recall -  0.38\n",
      "F1 -  0.1\n",
      "Jaccard -  0.05\n"
     ]
    }
   ],
   "source": [
    "evaluate(data['keywords'].tolist()[20:50], t_kws2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы видим, у нас приличный recall, а вот с precision беда.\n",
    "Так как результат не превосходит baseline уже сейчас, то мучить сервер и запускать на остальных данных, думаю, не стоит"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "texterra_kws_counter = [Counter(i).most_common(10) for i in t_kws2]\n",
    "texterra_kws_counter = [[j[0] for j in i] for i in texterra_kws_counter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision -  0.07\n",
      "Recall -  0.12\n",
      "F1 -  0.09\n",
      "Jaccard -  0.05\n"
     ]
    }
   ],
   "source": [
    "evaluate(data['keywords'].tolist()[20:50], texterra_kws_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
